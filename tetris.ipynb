{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee529aff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:32.050083Z",
     "start_time": "2022-09-24T21:33:32.041140Z"
    }
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# path = \"/content/drive/MyDrive/code/\"\n",
    "path = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c24e09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:32.055998Z",
     "start_time": "2022-09-24T21:33:32.052536Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install d2l==1.0.0-alpha1.post0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27b4a06f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:32.060501Z",
     "start_time": "2022-09-24T21:33:32.057852Z"
    }
   },
   "outputs": [],
   "source": [
    "# some code borrowed from\n",
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "# and http://d2l.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35b2b208",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.905901Z",
     "start_time": "2022-09-24T21:33:32.063367Z"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf270f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.912201Z",
     "start_time": "2022-09-24T21:33:34.908089Z"
    }
   },
   "outputs": [],
   "source": [
    "def add_to_class(Class):\n",
    "    def wrapper(obj):\n",
    "        setattr(Class, obj.__name__, obj)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c4c8430",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.918805Z",
     "start_time": "2022-09-24T21:33:34.914845Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788294c1",
   "metadata": {},
   "source": [
    "# tetris environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d972e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.929527Z",
     "start_time": "2022-09-24T21:33:34.922484Z"
    }
   },
   "outputs": [],
   "source": [
    "# piece is a tensor of coordinates with min x and y values being 0\n",
    "test = torch.tensor([[0,0],[0,1],[0,2],[1,1]])  # a T-piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c94af99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.934450Z",
     "start_time": "2022-09-24T21:33:34.931267Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_corner(piece):\n",
    "    return piece - piece.min(axis=0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "209b35d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.940717Z",
     "start_time": "2022-09-24T21:33:34.936503Z"
    }
   },
   "outputs": [],
   "source": [
    "def coords_to_2d(piece):\n",
    "    piece_2d = torch.zeros(*(piece.max(axis=0).values+1).tolist(), dtype=torch.uint8)\n",
    "    piece_2d[piece[:,0],piece[:,1]] = 1\n",
    "    return piece_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fdd1211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.946661Z",
     "start_time": "2022-09-24T21:33:34.942731Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_rotations(piece):\n",
    "    return [\n",
    "        coords_to_2d(\n",
    "            set_corner(piece @ torch.linalg.matrix_power(\n",
    "                torch.tensor([[0, 1], [-1, 0]]), i))) for i in range(4)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc93d0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.954415Z",
     "start_time": "2022-09-24T21:33:34.948590Z"
    }
   },
   "outputs": [],
   "source": [
    "def kill_duplicates(array):\n",
    "    # quick and dirty way of killing duplicate rotations\n",
    "    num_elems = len(array)\n",
    "    duplicated = []\n",
    "    for i in range(len(array)):\n",
    "        for j in range(i):\n",
    "            if torch.equal(array[i], array[j]):\n",
    "                duplicated.append(i)\n",
    "                break\n",
    "    return [array[i] for i in range(num_elems) if i not in duplicated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b874a2ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:34.961008Z",
     "start_time": "2022-09-24T21:33:34.956773Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualise(piece_2d):\n",
    "    print('\\n'.join(' '.join('%d' % x for x in y)\n",
    "                    for y in torch.flipud(piece_2d)).replace('0', '.').replace('1', '#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c87f5e1b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.001339Z",
     "start_time": "2022-09-24T21:33:34.964076Z"
    }
   },
   "outputs": [],
   "source": [
    "shapes = [\n",
    "        torch.tensor(_) for _ in [\n",
    "            [[0, 0], [0, 1], [0, 2], [0, 3]],  # I\n",
    "            [[1, 0], [0, 0], [0, 1], [0, 2]],  # J\n",
    "            [[0, 0], [0, 1], [0, 2], [1, 2]],  # L\n",
    "            [[0, 0], [0, 1], [1, 0], [1, 1]],  # O\n",
    "            [[0, 0], [0, 1], [1, 1], [1, 2]],  # S\n",
    "            [[1, 0], [1, 1], [0, 1], [0, 2]],  # Z\n",
    "            [[0, 0], [0, 1], [0, 2], [1, 1]],  # T\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "pieces_2d = [kill_duplicates(get_rotations(shapes[i])) for i in range(len(shapes))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5067ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.008973Z",
     "start_time": "2022-09-24T21:33:35.003378Z"
    }
   },
   "outputs": [],
   "source": [
    "class Playfield(d2l.HyperParameters):\n",
    "    global pieces_2d\n",
    "    def __init__(self, width=10, height=20, game_over_cost=200, clear_reward=10, pieces=pieces_2d):\n",
    "        self.save_hyperparameters()\n",
    "        self.board = torch.zeros(height, width, dtype=torch.uint8)\n",
    "        self.time_alive = 0\n",
    "        self.lines_cleared = 0\n",
    "        self.dead = False\n",
    "        self.memory = deque([], maxlen=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0af88ca0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.018677Z",
     "start_time": "2022-09-24T21:33:35.014571Z"
    }
   },
   "outputs": [],
   "source": [
    "@add_to_class(Playfield)\n",
    "def show_board(self):\n",
    "    visualise(self.board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6673027e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.025368Z",
     "start_time": "2022-09-24T21:33:35.020949Z"
    }
   },
   "outputs": [],
   "source": [
    "@add_to_class(Playfield)\n",
    "def reset_board(self):\n",
    "    self.board = torch.zeros(self.height, self.width, dtype=torch.uint8)\n",
    "    self.dead = False\n",
    "    self.time_alive, self.lines_cleared = 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02192ffc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.031448Z",
     "start_time": "2022-09-24T21:33:35.026725Z"
    }
   },
   "outputs": [],
   "source": [
    "def col_heights(board):\n",
    "    flipped = torch.flipud(board)\n",
    "    c_heights = (board.shape[0]-flipped.argmax(axis=0))*flipped.max(axis=0).values\n",
    "    c_holes = board.argmin(axis=0)+1\n",
    "    c_holes = c_holes*(c_holes < c_heights)\n",
    "    return c_heights, c_holes\n",
    "\n",
    "@add_to_class(Playfield)\n",
    "def heights(self):\n",
    "    return col_heights(self.board)[0]\n",
    "\n",
    "@add_to_class(Playfield)\n",
    "def holes(self):\n",
    "    return col_heights(self.board)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77666852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.039679Z",
     "start_time": "2022-09-24T21:33:35.035249Z"
    }
   },
   "outputs": [],
   "source": [
    "def clear_lines(board):\n",
    "    remaining = (board.sum(axis=1) != board.shape[1])\n",
    "    num_remaining = remaining.sum().item()\n",
    "    return F.pad(board[remaining, :],\n",
    "                 pad=(0, 0, 0, board.shape[0] -\n",
    "                      num_remaining)), board.shape[0]-num_remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7515bfeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.045585Z",
     "start_time": "2022-09-24T21:33:35.041849Z"
    }
   },
   "outputs": [],
   "source": [
    "def state_change(new_board, new_heights, new_holes, reward, cleared):\n",
    "    return {\n",
    "        'board': new_board,\n",
    "        'heights': new_heights,\n",
    "        'holes': new_holes,\n",
    "        'reward': reward,\n",
    "        'cleared': cleared\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c45a1ac7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.058517Z",
     "start_time": "2022-09-24T21:33:35.047136Z"
    }
   },
   "outputs": [],
   "source": [
    "@add_to_class(Playfield)\n",
    "def next_states(self, poly_num=None):\n",
    "    # Return a list of tuples (future board, future heights, reward, lines cleared).\n",
    "    # I set reward to be -(change in board heights),\n",
    "    # with the exception of a game over, in which reward is -game_over_cost.\n",
    "    board_heights = self.heights()\n",
    "    next_states = []\n",
    "    if not poly_num:\n",
    "        poly_num = random.randint(0, len(self.pieces) - 1)\n",
    "    polyomino = self.pieces[poly_num]\n",
    "    for rot in polyomino:\n",
    "        rot_height, rot_width = rot.shape\n",
    "        lower_boundary = rot.argmax(axis=0)\n",
    "        for i in range(self.width - rot_width + 1):\n",
    "            sitting_height = (board_heights[i:i + rot_width] -\n",
    "                              lower_boundary).max()\n",
    "            if sitting_height + rot_height < self.height:\n",
    "                new_board = self.board.clone()\n",
    "                new_board[torch.nonzero(rot)[:, 0] + sitting_height,\n",
    "                          torch.nonzero(rot)[:, 1] + i] = 1\n",
    "                new_board[:], cleared = clear_lines(new_board)\n",
    "                new_heights, new_holes = col_heights(new_board)\n",
    "#                 reward = torch.tensor(cleared * self.clear_reward)\n",
    "                reward = 0.1*(board_heights.sum() - new_heights.sum(\n",
    "                )) + cleared * self.clear_reward\n",
    "                next_states.append(\n",
    "                    state_change(new_board, new_heights, new_holes, reward, cleared))\n",
    "    if not (len(next_states)):\n",
    "        next_states = [\n",
    "            state_change(\n",
    "                torch.zeros(self.height, self.width, dtype=torch.uint8),\n",
    "                torch.zeros(self.width), torch.zeros(self.width), torch.tensor(-self.game_over_cost), 0)\n",
    "        ]\n",
    "        self.dead = True\n",
    "    return next_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b09b2a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.064581Z",
     "start_time": "2022-09-24T21:33:35.060505Z"
    }
   },
   "outputs": [],
   "source": [
    "@add_to_class(Playfield)\n",
    "def update_board_state(self, state):\n",
    "    # set the board to a state (chosen from next_states)\n",
    "    self.board = state['board']\n",
    "    self.lines_cleared += state['cleared']\n",
    "    self.time_alive += 1\n",
    "    if self.dead:\n",
    "        self.memory.append({'lines_cleared': self.lines_cleared, 'time_alive': self.time_alive})\n",
    "        self.reset_board()\n",
    "        # still need to write some code that tracks game statistics over multiple runs for the main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6438a0e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.302325Z",
     "start_time": "2022-09-24T21:33:35.067174Z"
    }
   },
   "outputs": [],
   "source": [
    "# To test everything works correctly so far, play by greedily choosing the action with highest immediate reward\n",
    "\n",
    "\n",
    "def greedy_step(pfield, printing=True):\n",
    "    next_states = pfield.next_states()\n",
    "    max_reward = max([x['reward'] for x in next_states])\n",
    "    pfield.update_board_state(\n",
    "        random.choice([x for x in next_states if x['reward'] == max_reward]))\n",
    "    if printing:\n",
    "        pfield.show_board()\n",
    "        print(\n",
    "            f\"{p.time_alive} piece drop{'' if pfield.time_alive==1 else 's'}, {pfield.lines_cleared} lines cleared\"\n",
    "        )\n",
    "\n",
    "\n",
    "p = Playfield()\n",
    "greedy_step(p,False)\n",
    "while p.time_alive:\n",
    "    greedy_step(p,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8d9a7a7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.307871Z",
     "start_time": "2022-09-24T21:33:35.304431Z"
    }
   },
   "outputs": [],
   "source": [
    "def state_to_float(state):\n",
    "    # in retrospect, this should have been a class, not a dictionary\n",
    "    return {\n",
    "        'board': state[board].float(),\n",
    "        'heights': state[heights].float(),\n",
    "        'holes': state[holes].float(),\n",
    "        'reward': reward,\n",
    "        'cleared': cleared\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "857a3ba4",
   "metadata": {},
   "source": [
    "# DQN setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98119a4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.312552Z",
     "start_time": "2022-09-24T21:33:35.309585Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47375a11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.318811Z",
     "start_time": "2022-09-24T21:33:35.314175Z"
    }
   },
   "outputs": [],
   "source": [
    "# this is a bit different to the usual transition because the action is\n",
    "# completely characterised by the next state, so we just drop action\n",
    "# reward is also gone because \"next_states\" are tuples anyway\n",
    "Transition = namedtuple('Transition', ('state', 'next_states'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5ba46150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.324324Z",
     "start_time": "2022-09-24T21:33:35.320826Z"
    }
   },
   "outputs": [],
   "source": [
    "# write DQN with lazy, also do some conv on heights and stuff\n",
    "# also need to pass in height data (maybe hole data? this is encapsuled somewhat in the loss function though)\n",
    "# maybe i should multiply cost of holes (e.g. by adding multiples of (cost-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "000e9113",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.334930Z",
     "start_time": "2022-09-24T21:33:35.326615Z"
    }
   },
   "outputs": [],
   "source": [
    "class heights_CNN(nn.Module):\n",
    "    def __init__(self, c1=256, c2=128, c3=512-20, c4=20, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = nn.LazyConv1d(c1, kernel_size=3, padding=0, stride=1)\n",
    "        self.conv2 = nn.LazyConv1d(c2, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn1 = nn.LazyBatchNorm1d()\n",
    "        self.bn2 = nn.LazyBatchNorm1d()\n",
    "        self.out_layer = nn.LazyLinear(c3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        y = F.relu(self.bn1(self.conv1(x)))\n",
    "        y = F.relu(self.bn2(self.conv2(y)))\n",
    "        y = torch.flatten(y,1,2)\n",
    "        y = F.relu(self.out_layer(y))\n",
    "        y = torch.concat((y,torch.squeeze(x.flatten(1,2),dim=1)),dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "927a261a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.339417Z",
     "start_time": "2022-09-24T21:33:35.336690Z"
    }
   },
   "outputs": [],
   "source": [
    "class column_conv(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64704424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.349317Z",
     "start_time": "2022-09-24T21:33:35.341453Z"
    }
   },
   "outputs": [],
   "source": [
    "class board_CNN(nn.Module):\n",
    "    def __init__(self, c1=64, c2=32, c3=32, c4=32, c5=512, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.conv1 = nn.LazyConv2d(c1, kernel_size=3, padding=0, stride=1)\n",
    "        self.conv2 = nn.LazyConv2d(c2, kernel_size=3, padding=1, stride=2)\n",
    "        self.conv3 = nn.LazyConv2d(c3, kernel_size=(3,1), padding=0, stride=2)\n",
    "        self.conv4 = nn.LazyConv2d(c4, kernel_size=3, padding=1, stride=1)\n",
    "        self.bn1 = nn.LazyBatchNorm2d()\n",
    "        self.bn2 = nn.LazyBatchNorm2d()\n",
    "        self.bn3 = nn.LazyBatchNorm2d()\n",
    "        self.bn4 = nn.LazyBatchNorm2d()\n",
    "        self.out_layer = nn.LazyLinear(c5)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        y = F.pad(x,(1,1,1,0),value=1)\n",
    "        y = F.relu(self.bn1(self.conv1(y)))\n",
    "        y = F.relu(self.bn2(self.conv2(y)))\n",
    "        y = F.relu(self.bn3(self.conv3(y)))\n",
    "        y = F.relu(self.bn4(self.conv4(y)))\n",
    "        y = torch.flatten(y,1,3)\n",
    "        y = F.relu(self.out_layer(y))\n",
    "#         y = torch.concat((y,torch.squeeze(x,dim=1)),dim=1)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da61728e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.358660Z",
     "start_time": "2022-09-24T21:33:35.351699Z"
    }
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, lr=1e-4, width=128, loss_mem_length=100, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.height_net = heights_CNN(64,64,128-20,20)\n",
    "        self.board_net = board_CNN(32,32,16,16,128)\n",
    "        self.dense1 = nn.LazyLinear(width)\n",
    "        self.dense2 = nn.LazyLinear(width)\n",
    "        self.out = nn.LazyLinear(1)\n",
    "        self.optimiser = optim.RMSprop(self.parameters(),weight_decay=5e-5,lr=lr)\n",
    "        self.loss_memory = deque([], maxlen=loss_mem_length)\n",
    "    \n",
    "    def forward(self, height_tensor, board_tensor):\n",
    "        height_tensor = height_tensor.to(device)\n",
    "        board_tensor = board_tensor.to(device)\n",
    "        h = self.height_net(height_tensor)\n",
    "        b = self.board_net(board_tensor)\n",
    "        y = torch.cat((h,b),1)\n",
    "        y = F.relu(self.dense1(y))\n",
    "        y = F.relu(self.dense2(y))\n",
    "        y = self.out(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7e83ded",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.364032Z",
     "start_time": "2022-09-24T21:33:35.361011Z"
    }
   },
   "outputs": [],
   "source": [
    "@add_to_class(DQN)\n",
    "def loss(self, y_hat, y):\n",
    "    fn = nn.SmoothL1Loss()\n",
    "    return fn(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee2b5dd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.369499Z",
     "start_time": "2022-09-24T21:33:35.365719Z"
    }
   },
   "outputs": [],
   "source": [
    "@add_to_class(DQN)\n",
    "def train_step(self, batch_loss):\n",
    "    self.optimiser.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    for param in self.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    self.optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4ede33c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.434644Z",
     "start_time": "2022-09-24T21:33:35.371387Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch size, num channels\n",
    "test_cnn = heights_CNN()\n",
    "test_heights = torch.concat(\n",
    "    (p.heights().reshape(1, 1, -1) * torch.tensor([[[1]], [[1]]]).float(),\n",
    "     p.holes().reshape(1, 1, -1) * torch.tensor([[[1]], [[1]]]).float()), 1)\n",
    "test_cnn(test_heights).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "353e8687",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.449102Z",
     "start_time": "2022-09-24T21:33:35.436258Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_cnn_2 = board_CNN()\n",
    "test_boards = p.board.reshape(1,1,p.board.shape[0],p.board.shape[1])*torch.tensor([[[[1]]],[[[1]]]]).float()\n",
    "test_cnn_2(test_boards).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2917bbee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.455973Z",
     "start_time": "2022-09-24T21:33:35.451114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1, 20, 10]), torch.Size([2, 2, 10]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_boards.shape,test_heights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d7da74a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.482479Z",
     "start_time": "2022-09-24T21:33:35.458851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dqn = DQN()\n",
    "test_heights = torch.concat(\n",
    "    (p.heights().reshape(1, 1, -1) * torch.tensor([[[1]], [[1]]]).float(),\n",
    "     p.holes().reshape(1, 1, -1) * torch.tensor([[[1]], [[1]]]).float()), 1)\n",
    "test_boards = p.board.reshape(1,1,p.board.shape[0],p.board.shape[1])*torch.tensor([[[[1]]],[[[1]]]]).float()\n",
    "test_dqn(test_heights, test_boards).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89e1e236",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.488668Z",
     "start_time": "2022-09-24T21:33:35.484556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156333"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_parameters(test_dqn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf66459c",
   "metadata": {},
   "source": [
    "# set up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d01f395",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.513271Z",
     "start_time": "2022-09-24T21:33:35.490332Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.01\n",
    "EPS_DECAY = 200\n",
    "\n",
    "BOARD_WIDTH = 10\n",
    "BOARD_HEIGHT = 20\n",
    "GAME_OVER_COST = 200\n",
    "CLEAR_REWARD = 10\n",
    "\n",
    "MOVES_PER_TRAIN = 50\n",
    "\n",
    "Q_net = DQN()\n",
    "p = Playfield(width=BOARD_WIDTH, height=BOARD_HEIGHT, game_over_cost=GAME_OVER_COST, clear_reward=CLEAR_REWARD)\n",
    "init_heights = torch.concat(\n",
    "    (p.heights().reshape(1, 1, -1) * torch.tensor([[[1]]]).float(),\n",
    "     p.holes().reshape(1, 1, -1) * torch.tensor([[[1]]]).float()), 1)\n",
    "init_boards = p.board.reshape(1,1,p.board.shape[0],p.board.shape[1])*torch.tensor([[[[1]]]]).float()\n",
    "# print(init_heights.shape,init_boards.shape)\n",
    "Q_net(init_heights,init_boards)\n",
    "Q_net.apply(d2l.init_cnn)\n",
    "\n",
    "memory = ReplayMemory(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "403204ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.528547Z",
     "start_time": "2022-09-24T21:33:35.523237Z"
    }
   },
   "outputs": [],
   "source": [
    "def next_states_to_tensors(states):\n",
    "    out = {\n",
    "        'board_tensor':\n",
    "        torch.concat(\n",
    "            tuple(t['board'].reshape(1, 1, BOARD_HEIGHT, BOARD_WIDTH)\n",
    "                  for t in states)).float(),\n",
    "        'heights_tensor':\n",
    "        torch.concat(\n",
    "            tuple(\n",
    "                torch.concat((t['heights'].reshape(1, 1, BOARD_WIDTH),\n",
    "                              t['holes'].reshape(1, 1, BOARD_WIDTH)), 1)\n",
    "                for t in states)).float(),\n",
    "        'reward_tensor':\n",
    "        torch.concat(tuple(t['reward'].reshape(1,1) for t in states))\n",
    "    }\n",
    "#     print(out['heights_tensor'].shape)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7ad35b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.533392Z",
     "start_time": "2022-09-24T21:33:35.530365Z"
    }
   },
   "outputs": [],
   "source": [
    "def q_value_single(state):\n",
    "    return Q_net(torch.concat((state['heights'],state['holes']),1), state['board'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "395980e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.545412Z",
     "start_time": "2022-09-24T21:33:35.535731Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use epsilon-greedy. I might implement a policy that chooses moves with probability dependent on Q later\n",
    "# (hm maybe i could also have a chance of running the step with highest reward, seems good for convergence)\n",
    "def do_action(eps1, eps2, gamma=GAMMA):\n",
    "    # eps1 is the probability of doing the move with the highest immediate value\n",
    "    # eps2 is the probability of doing a completely random move\n",
    "    heights, holes = p.heights(), p.holes()\n",
    "    now_state = {\n",
    "            'board': p.board.reshape(1, 1, BOARD_HEIGHT, BOARD_WIDTH).float(),\n",
    "            'heights': heights.reshape(1, 1, BOARD_WIDTH).float(),\n",
    "            'holes': holes.reshape(1, 1, BOARD_WIDTH).float(),\n",
    "        }\n",
    "    next_polyomino = random.randint(0, len(p.pieces) - 1)\n",
    "    next_states = p.next_states(next_polyomino)\n",
    "    memory.push(now_state, next_states)\n",
    "    next_states_tensors = next_states_to_tensors(next_states)\n",
    "    heights_tensor = next_states_tensors['heights_tensor']\n",
    "    board_tensor = next_states_tensors['board_tensor']\n",
    "    reward_tensor = next_states_tensors['reward_tensor']\n",
    "    if random.random() > eps1+eps2:\n",
    "        future_q_values = Q_net(heights_tensor, board_tensor)\n",
    "        move_values = gamma*future_q_values+reward_tensor\n",
    "        action = next_states[future_q_values.argmax()]\n",
    "    elif random.random() > eps1:\n",
    "        action = random.choice(next_states)\n",
    "    else:\n",
    "        max_reward = max([x['reward'] for x in next_states])\n",
    "        action = random.choice([x for x in next_states if x['reward'] == max_reward])\n",
    "    p.update_board_state(action)\n",
    "#     p.show_board()\n",
    "#     return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1b101f69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.570407Z",
     "start_time": "2022-09-24T21:33:35.547090Z"
    }
   },
   "outputs": [],
   "source": [
    "do_action(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18b44ca3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.575963Z",
     "start_time": "2022-09-24T21:33:35.572523Z"
    }
   },
   "outputs": [],
   "source": [
    "# for i in range(128):\n",
    "#     do_action()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77bf4ed1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.586061Z",
     "start_time": "2022-09-24T21:33:35.577783Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_Q_net(gamma, min_memory):\n",
    "    if len(memory) < min_memory:\n",
    "        return\n",
    "\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    board_batches = [\n",
    "        next_states_to_tensors(transition[1])['board_tensor']\n",
    "        for transition in transitions\n",
    "    ]\n",
    "    height_batches = [\n",
    "        next_states_to_tensors(transition[1])['heights_tensor']\n",
    "        for transition in transitions\n",
    "    ]\n",
    "\n",
    "    now_q_values = torch.concat(\n",
    "        tuple(q_value_single(transitions[i][0]) for i in range(BATCH_SIZE)))\n",
    "\n",
    "    future_q_values = [\n",
    "        Q_net(height_batches[i], board_batches[i]) for i in range(BATCH_SIZE)\n",
    "    ]  # list (of length BATCH_SIZE) of tensors of q_values\n",
    "\n",
    "    actions = [\n",
    "        transitions[i][1][future_q_values[i].argmax()]\n",
    "        for i in range(BATCH_SIZE)\n",
    "    ]  # the future states chosen by the Q-net in each state in the batch\n",
    "\n",
    "    rewards = torch.concat(tuple(t['reward'].reshape(1, -1) for t in actions))\n",
    "\n",
    "    v_values = torch.concat(\n",
    "        tuple(\n",
    "            Q_net(\n",
    "                torch.concat((\n",
    "                    actions[i]['heights'].reshape(1, 1, BOARD_WIDTH).float(),\n",
    "                    actions[i]['holes'].reshape(1, 1, BOARD_WIDTH).float()\n",
    "                ), 1), actions[i]['board'].reshape(1, 1, BOARD_HEIGHT,\n",
    "                                                   BOARD_WIDTH).float())\n",
    "            for i in range(BATCH_SIZE)))\n",
    "\n",
    "    q_loss = Q_net.loss(now_q_values, rewards + gamma * v_values)\n",
    "\n",
    "    Q_net.train_step(q_loss)\n",
    "\n",
    "    Q_net.loss_memory.append(q_loss.detach().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e43dc32c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:35.590991Z",
     "start_time": "2022-09-24T21:33:35.588493Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_Q_net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa68160",
   "metadata": {},
   "source": [
    "# training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2efbdbc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.508345Z",
     "start_time": "2022-09-24T21:33:35.592718Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lines_cleared': 0, 'time_alive': 24}\n",
      "num_steps: 2600, eps_thresh: 0.9286571387821183, loss: 3.124517046742969\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . . . . . . . .\n",
      ". . . # . . # # # .\n",
      ". . # # . . # . . .\n",
      ". . # # # # # # . .\n",
      ". # # # # # # # . .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/bh/tpcchpzx0txc5bh9rkqdnf640000gp/T/ipykernel_4752/3281855738.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m#         do_action(eps_thresh * eps_thresh, eps_thresh * (1-eps_thresh))  # i should make it greedy first then switch over\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mnum_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mtrain_Q_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGAMMA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bh/tpcchpzx0txc5bh9rkqdnf640000gp/T/ipykernel_4752/2009033974.py\u001b[0m in \u001b[0;36mtrain_Q_net\u001b[0;34m(gamma, min_memory)\u001b[0m\n\u001b[1;32m     17\u001b[0m         tuple(q_value_single(transitions[i][0]) for i in range(BATCH_SIZE)))\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     future_q_values = [\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mQ_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     ]  # list (of length BATCH_SIZE) of tensors of q_values\n",
      "\u001b[0;32m/var/folders/bh/tpcchpzx0txc5bh9rkqdnf640000gp/T/ipykernel_4752/2009033974.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     future_q_values = [\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mQ_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboard_batches\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     ]  # list (of length BATCH_SIZE) of tensors of q_values\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bh/tpcchpzx0txc5bh9rkqdnf640000gp/T/ipykernel_4752/943728816.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, height_tensor, board_tensor)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mheight_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mheight_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mboard_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboard_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheight_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboard_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/bh/tpcchpzx0txc5bh9rkqdnf640000gp/T/ipykernel_4752/3652983971.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m         \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m         return F.batch_norm(\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             \u001b[0;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2436\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2438\u001b[0;31m     return torch.batch_norm(\n\u001b[0m\u001b[1;32m   2439\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2440\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "GAMMA = 0.95\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 100000\n",
    "\n",
    "BOARD_WIDTH = 10\n",
    "BOARD_HEIGHT = 20\n",
    "GAME_OVER_COST = 100\n",
    "CLEAR_REWARD = 10\n",
    "\n",
    "MOVES_PER_TRAIN = 200\n",
    "\n",
    "LOAD_PARAMS = False\n",
    "# change this to True to load a previously saved model\n",
    "\n",
    "Q_net = DQN(loss_mem_length=20)\n",
    "p = Playfield(width=BOARD_WIDTH,\n",
    "              height=BOARD_HEIGHT,\n",
    "              game_over_cost=GAME_OVER_COST,\n",
    "              clear_reward=CLEAR_REWARD)\n",
    "init_heights = torch.concat((p.heights().reshape(\n",
    "    1, 1, -1).float(), p.holes().reshape(1, 1, -1).float()), 1)\n",
    "init_boards = p.board.reshape(1, 1, p.board.shape[0],\n",
    "                              p.board.shape[1]) * torch.tensor([[[[1]]]\n",
    "                                                                ]).float()\n",
    "\n",
    "if LOAD_PARAMS:\n",
    "    Q_net.load_state_dict(torch.load(f'{path}Q_net.params'))\n",
    "    with open(f\"{path}num_steps.txt\", \"r\") as f:\n",
    "        num_steps = int(f.readlines()[0])\n",
    "else:\n",
    "    Q_net.apply(d2l.init_cnn)\n",
    "    Q_net(init_heights, init_boards)\n",
    "    num_steps = 0\n",
    "\n",
    "memory = ReplayMemory(5000)\n",
    "\n",
    "# num_steps = 0\n",
    "while True:\n",
    "    eps_thresh = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * num_steps / EPS_DECAY)\n",
    "    for i in range(MOVES_PER_TRAIN):\n",
    "#         do_action(0.04, 0.04, GAMMA)\n",
    "        do_action(eps_thresh * 0.5, eps_thresh * 0.5)\n",
    "        #         do_action(eps_thresh * eps_thresh, eps_thresh * (1-eps_thresh))  # i should make it greedy first then switch over\n",
    "        num_steps += 1\n",
    "    train_Q_net(GAMMA, 1000)\n",
    "    if num_steps % 100 == 0:\n",
    "        clear_output(wait=True)\n",
    "        print(p.memory[-1])\n",
    "        print(\n",
    "            f\"num_steps: {num_steps}, eps_thresh: {eps_thresh}, loss: {sum(Q_net.loss_memory)/max(len(Q_net.loss_memory),1)}\"\n",
    "        )\n",
    "        p.show_board()\n",
    "    if num_steps % 2000 == 0:\n",
    "        torch.save(Q_net.state_dict(), f'{path}Q_net.params')\n",
    "        with open(f\"{path}num_steps.txt\", \"w\") as f:\n",
    "            f.write(str(num_steps))\n",
    "    if num_steps % 100000 == 0:\n",
    "        torch.save(Q_net.state_dict(), f'{path}Q_net_{num_steps}.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ecba7",
   "metadata": {},
   "source": [
    "# meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e800bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.510872Z",
     "start_time": "2022-09-24T21:33:55.510847Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "mem_sizes = sorted([\n",
    "    (x, sys.getsizeof(globals().get(x))) for x in dir()\n",
    "    if not x.startswith('_') and x not in sys.modules and x not in ipython_vars\n",
    "],\n",
    "                   key=lambda x: x[1],\n",
    "                   reverse=True)\n",
    "[print(thing[0],f\"{thing[1]/1000} MB\") for thing in mem_sizes if thing[1] > 1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4734ce6e",
   "metadata": {},
   "source": [
    "# old stuff that i probably don't need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80280651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.512740Z",
     "start_time": "2022-09-24T21:33:55.512719Z"
    }
   },
   "outputs": [],
   "source": [
    "# old stuff, worry about it later\n",
    "\n",
    "# concatenate the BATCH_SIZE sets of future boards into a single tensor\n",
    "# same for heights\n",
    "# later we will run Q on these as a group of concatenated batches...\n",
    "# wait this breaks batchnorm doesn't it rip\n",
    "\n",
    "# test_boards = torch.concat(\n",
    "#     tuple(t['board'].reshape(1, 1, BOARD_HEIGHT, BOARD_WIDTH)\n",
    "#           for transition in test_transitions for t in transition[1])).float()\n",
    "# test_heights = torch.concat(\n",
    "#     tuple(t['heights'].reshape(1, 1, BOARD_WIDTH)\n",
    "#           for transition in test_transitions for t in transition[1])).float()\n",
    "# test_lengths = torch.tensor([0]+[len(t[1]) for t in test_transitions]).cumsum(0)\n",
    "# test_lengths\n",
    "# test_q_values = Q_net(test_heights, test_boards)\n",
    "# test_q_values.shape\n",
    "# these two should be the same if everything is working correctly\n",
    "# test_boards[test_lengths[10]:test_lengths[11]], tuple(t['board'] for t in test_transitions[10][1])\n",
    "# [test_q_values[test_lengths[i]:test_lengths[i+1]].argmax() for i in range(BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61fe886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.513774Z",
     "start_time": "2022-09-24T21:33:55.513760Z"
    }
   },
   "outputs": [],
   "source": [
    "# d2l.init_cnn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89589885",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.515193Z",
     "start_time": "2022-09-24T21:33:55.515169Z"
    }
   },
   "outputs": [],
   "source": [
    "# d2l.Classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7382fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0f0575",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.516452Z",
     "start_time": "2022-09-24T21:33:55.516435Z"
    }
   },
   "outputs": [],
   "source": [
    "# # testing batch of transitions\n",
    "# test_transitions = [\n",
    "#     Transition(\n",
    "#         {\n",
    "#             'board': p.board.reshape(1, 1, BOARD_HEIGHT, BOARD_WIDTH).float(),\n",
    "#             'heights': p.heights().reshape(1, 1, BOARD_WIDTH).float()\n",
    "#         }, p.next_states()) for i in range(BATCH_SIZE)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b72944",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.518215Z",
     "start_time": "2022-09-24T21:33:55.518195Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_board_batches = [\n",
    "#     next_states_to_tensors(transition[1])['board_tensor']\n",
    "#     for transition in test_transitions\n",
    "# ]\n",
    "# test_height_batches = [\n",
    "#     next_states_to_tensors(transition[1])['heights_tensor']\n",
    "#     for transition in test_transitions\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b0218",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.519540Z",
     "start_time": "2022-09-24T21:33:55.519527Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_now_q_values = torch.concat(\n",
    "#     tuple(q_value_single(test_transitions[i][0]) for i in range(BATCH_SIZE))\n",
    "# )\n",
    "\n",
    "# test_future_q_values = [\n",
    "#     Q_net(test_height_batches[i], test_board_batches[i])\n",
    "#     for i in range(BATCH_SIZE)\n",
    "# ]  # list (of length BATCH_SIZE) of tensors of q_values\n",
    "\n",
    "# test_actions = [\n",
    "#     test_transitions[i][1][test_future_q_values[i].argmax()]\n",
    "#     for i in range(BATCH_SIZE)\n",
    "# ]  # the future states chosen by the Q-net in each state in the batch\n",
    "\n",
    "# test_rewards = torch.concat(\n",
    "#     tuple(\n",
    "#         t['reward'].reshape(1,-1) for t in test_actions\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# test_v_values = torch.concat(\n",
    "#     tuple(\n",
    "#         Q_net(\n",
    "#             test_actions[i]['heights'].reshape(\n",
    "#                 1, 1, BOARD_WIDTH).float(), test_actions[i]['board'].reshape(\n",
    "#                     1, 1, BOARD_HEIGHT, BOARD_WIDTH).float())\n",
    "#         for i in range(BATCH_SIZE)))\n",
    "\n",
    "# # test_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af5f1c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.521047Z",
     "start_time": "2022-09-24T21:33:55.521031Z"
    }
   },
   "outputs": [],
   "source": [
    "# # use huber\n",
    "# loss_fn = nn.SmoothL1Loss()\n",
    "# test_loss = loss_fn(test_now_q_values, (test_rewards + GAMMA*test_v_values))\n",
    "# test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee33a00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-24T21:33:55.522328Z",
     "start_time": "2022-09-24T21:33:55.522314Z"
    }
   },
   "outputs": [],
   "source": [
    "# Q_net.train_step(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaf5680",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
